{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\33678\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dossiers source et destination\n",
    "source_dir = 'data'  \n",
    "dest_dir = 'data_face'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_img(img, scale_percent):\n",
    "\n",
    "    # Réduire la résolution de l'image\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "\n",
    "    # Redimensionner l'image\n",
    "    resized_img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Convertir l'image redimensionnée en RGB\n",
    "    resized_img_rgb = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return resized_img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces_from_photo(path_img, output_dir, model_used=\"retinaface\", align=True):\n",
    "\n",
    "    # Ouvrir l'image\n",
    "    img_cv2 = cv2.imread(path_img)\n",
    "\n",
    "    # Vérifier si l'image a été chargée correctement\n",
    "    if img_cv2 is None:\n",
    "        print(f\"Erreur de chargement de l'image : {path_img}\")\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Redimensionner l'image\n",
    "    img_reduc = reduction_img(img_rgb, 5)\n",
    "\n",
    "    # Suivi\n",
    "    print(f\"Extraction des visages de la photo : {path_img}\")\n",
    "\n",
    "    # Détecter les visages\n",
    "    face_detected = DeepFace.extract_faces(\n",
    "        img_path = img_reduc, \n",
    "        detector_backend = model_used,\n",
    "        align = align,\n",
    "    )\n",
    "    \n",
    "    face_detected[0]\n",
    "\n",
    "    nb_face_detected = len(face_detected)\n",
    "    \n",
    "    if nb_face_detected == 0:\n",
    "        print(\"Pas de visages détecté\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Nombre de visages détecté : {nb_face_detected}\")\n",
    "\n",
    "    # Sauvegarder chaque visage détecté\n",
    "    for i, face in enumerate(face_detected):\n",
    "        facial_area = face['facial_area']\n",
    "        # Ajuster les coordonnées en fonction du facteur de réduction\n",
    "        x = int(facial_area['x'] * 95)\n",
    "        y = int(facial_area['y'] * 95)\n",
    "        w = int(facial_area['w'] * 95)\n",
    "        h = int(facial_area['h'] * 95)\n",
    "        cropped_face = img_rgb[y:y + h, x:x + w]\n",
    "        face_output_path = os.path.join(output_dir, f\"{path_img[-12:-4]}_face_{i+1}.jpg\")\n",
    "        cv2.imwrite(face_output_path, cropped_face)\n",
    "        print(f\"Visage {i+1} enregistré sous : {face_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des visages de la photo : data\\24_10_09 Soiree oeno\\IMG_2731.JPG\n",
      "Nombre de visages détecté : 1\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:786: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     11\u001b[0m             img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file)\n\u001b[1;32m---> 12\u001b[0m             \u001b[43mextract_faces_from_photo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Extrait les visages\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraitement terminé. Les visages sont sauvegardés dans :\u001b[39m\u001b[38;5;124m\"\u001b[39m, dest_dir)\n",
      "Cell \u001b[1;32mIn[16], line 45\u001b[0m, in \u001b[0;36mextract_faces_from_photo\u001b[1;34m(path_img, output_dir, model_used, align)\u001b[0m\n\u001b[0;32m     43\u001b[0m cropped_face \u001b[38;5;241m=\u001b[39m img_rgb[y:y \u001b[38;5;241m+\u001b[39m h, x:x \u001b[38;5;241m+\u001b[39m w]\n\u001b[0;32m     44\u001b[0m face_output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_img[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m12\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_face_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_output_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped_face\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m enregistré sous : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mface_output_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:786: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    }
   ],
   "source": [
    "# Parcourir le dossier source et traiter les images\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    relative_path = os.path.relpath(root, source_dir)\n",
    "\n",
    "    # Création du dossier de sauvegarde des faces\n",
    "    output_dir = os.path.join(dest_dir, relative_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for file in files:\n",
    "        if file.lower().endswith('.jpg'):\n",
    "            img_path = os.path.join(root, file)\n",
    "            extract_faces_from_photo(img_path, output_dir, align=True)  # Extrait les visages\n",
    "        break\n",
    "\n",
    "print(\"Traitement terminé. Les visages sont sauvegardés dans :\", dest_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
